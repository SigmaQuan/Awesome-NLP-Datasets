# Awesome question answering, machine reading, and dialog datasets


## SQuAD 
Stanford Question Answering Dataset (SQuAD) is a reading comprehension dataset, consisting of questions posed by crowdworkers on a set of Wikipedia articles, where the answer to every question is a segment of text, or span, from the corresponding reading passage, or the question might be unanswerable.

This dataset is created by [Pranav Rajpurkar](Pranav Rajpurkar), and can be download from the author's [github page](https://rajpurkar.github.io/SQuAD-explorer/).


## NarrativeQA
[paper](https://arxiv.org/pdf/1712.07040.pdf)


## RACE: 
[paper](http://aclweb.org/anthology/D17-1082)
We present RACE, a new dataset for
benchmark evaluation of methods in the
reading comprehension task. Collected
from the English exams for middle and
high school Chinese students in the age
range between 12 to 18, RACE consists of near 28,000 passages and near
100,000 questions generated by human
experts (English instructors), and covers a variety of topics which are carefully designed for evaluating the students’
ability in understanding and reasoning.
In particular, the proportion of questions
that requires reasoning is much larger
in RACE than that in other benchmark
datasets for reading comprehension, and
there is a significant gap between the
performance of the state-of-the-art models (43%) and the ceiling human performance (95%). We hope this new dataset
can serve as a valuable resource for research and evaluation in machine comprehension. The dataset is freely available at http://www.cs.cmu.edu/
˜glai1/data/race/ and the code is
available at https://github.com/
qizhex/RACE_AR_baselines


## TriviaQA
[paper](http://www.aclweb.org/anthology/P17-1147)


## WikiHop: Constructing Datasets for Multi-hop Reading Comprehension Across Documents
[paper](https://arxiv.org/pdf/1710.06481.pdf)


## SearchQA
[paper](https://arxiv.org/pdf/1704.05179.pdf)


## WIKIREADING:  A Novel Large-scale Language Understanding Task over Wikipedia
[paper](http://www.aclweb.org/anthology/P16-1145)

## NewsQA:
[paper](https://arxiv.org/pdf/1611.09830.pdf)


## MS MARCO
[paper](https://arxiv.org/pdf/1611.09268.pdf)


## The (6) dialog bAbI tasks
This dataset contains six tasks and each task is used to test a unique aspect of dialog. Tasks are designed to complement the set of 20 bAbI tasks for story understanding of the previous section.

For each task, there are 1000 dialogs for training, 1000 for development and 1000 for testing. For tasks 1-5, we also include a second test set (with suffix -OOV.txt) that contains dialogs including entities not present in training and development sets.

The detail description can be find in the paper:
Antoine Bordes, Y-Lan Boureau, Jason Weston, [Learning End-to-End Goal-Oriented Dialog](https://arxiv.org/pdf/1605.07683.pdf) and [Facebook](https://research.fb.com/publications/learning-end-to-end-goal-oriented-dialog/).


## CNN/Daily Mail: 
[paper](https://arxiv.org/pdf/1506.03340.pdf)


## The Movie Dialog dataset
Movie Dialog dataset (MDD) is designed to measure how well models can perform at goal and non-goal orientated dialog centered around the topic of movies (question answering, recommendation and discussion). Details and baseline results on this dataset can be found in the paper:

Jesse Dodge, Andreea Gane, Xiang Zhang, Antoine Bordes, Sumit Chopra, Alexander Miller, Arthur Slam, Jason Weston. [Evaluating Prerequisite Qualities for Learning End-to-End Dialog Systems](http://arxiv.org/abs/1511.06931) and the [page](https://research.fb.com/publications/evaluating-prerequisite-qualities-for-learning-end-to-end-dialog-systems/).

The file format is again the same as in the bAbI tasks. The IDs for a given dialog start at 1 and increase. Each ID consists of one turn for each speaker (an “exchange”), which are tab separated. When the IDs in a file reset back to 1 you can consider the following sentences as a new conversation.


## CBT
[paper](https://arxiv.org/pdf/1511.02301.pdf)


## The (20) QA bAbI tasks
This dataset is constructed by [Facebook](https://research.fb.com/downloads/babi/). The tasks are described in detail in the paper:
Jason Weston, et. al,. [Towards AI Complete Question Answering: A Set of Prerequisite Toy Tasks](http://arxiv.org/abs/1502.05698).



## MCTest
[paper](http://aclweb.org/anthology/D/D13/D13-1020.pdf)
